# Config Fields: Complete Guide

Understanding the difference between config key, `id`, and `name` fields in OpenCode model configuration.

## The Three Fields

```json
{
  "provider": {
    "openai": {
      "models": {
        "THIS-IS-THE-CONFIG-KEY": {
          "id": "this-is-the-id-field",
          "name": "This is the name field"
        }
      }
    }
  }
}
```

---

## What Each Field Controls

### Config Key (Property Name)

**Example:** `"gpt-5-codex-low"`

**Used For:**
- âœ… CLI `--model` flag: `--model=openai/gpt-5-codex-low`
- âœ… OpenCode internal lookups: `provider.info.models["gpt-5-codex-low"]`
- âœ… TUI persistence: Saved to `~/.opencode/tui` as `model_id = "gpt-5-codex-low"`
- âœ… Custom command frontmatter: `model: openai/gpt-5-codex-low`
- âœ… Agent configuration: `"model": "openai/gpt-5-codex-low"`
- âœ… **Plugin config lookup**: `userConfig.models["gpt-5-codex-low"]`
- âœ… Passed to custom loaders: `getModel(sdk, "gpt-5-codex-low")`

**This is the PRIMARY identifier throughout OpenCode!**

---

### `id` Field (Optional - NOT NEEDED for OpenAI)

**Example:** `"gpt-5-codex"`

**What it's used for:**
- âš ï¸ **Other providers**: Some providers use this for `sdk.languageModel(id)`
- âš ï¸ **Sorting**: Used for model priority sorting in OpenCode
- âš ï¸ **Documentation**: Indicates the "canonical" model ID

**What it's NOT used for with OpenAI:**
- âŒ **NOT sent to AI SDK** (config key is sent instead)
- âŒ **NOT used by plugin** (plugin receives config key)
- âŒ **NOT required** (OpenCode defaults it to config key)

**Code Reference:** (`tmp/opencode/packages/opencode/src/provider/provider.ts:252`)
```typescript
const parsedModel: ModelsDev.Model = {
  id: model.id ?? modelID,  // â† Defaults to config key if omitted
  ...
}
```

**OpenAI Custom Loader:** (`tmp/opencode/packages/opencode/src/provider/provider.ts:58-65`)
```typescript
openai: async () => {
  return {
    async getModel(sdk: any, modelID: string) {
      return sdk.responses(modelID)  // â† Receives CONFIG KEY, not id field!
    }
  }
}
```

**Our plugin receives:** `body.model = "gpt-5-codex-low"` (config key, NOT id field)

**Recommendation:** **Omit the `id` field** for OpenAI provider - it's redundant and creates confusion. OpenCode will auto-set it to the config key.

---

### `name` Field (Optional)

**Example:** `"GPT 5 Codex Low (OAuth)"`

**Used For:**
- âœ… **TUI Model Picker**: Display name shown in the model selection UI
- â„¹ï¸ **Documentation**: Human-friendly description

**Code Reference:** (`tmp/opencode/packages/opencode/src/provider/provider.ts:253`)
```typescript
const parsedModel: ModelsDev.Model = {
  name: model.name ?? existing?.name ?? modelID,  // Defaults to config key
  ...
}
```

**If omitted:** Falls back to config key for display

---

## Complete Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    What Users See & Use                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  CLI Usage:                                                     â”‚
â”‚  $ opencode run --model=openai/gpt-5-codex-low                 â”‚
â”‚                                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                   CONFIG KEY                    â”‚
â”‚                                                                 â”‚
â”‚  TUI Display:                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ Select Model:                    â”‚                          â”‚
â”‚  â”‚                                  â”‚                          â”‚
â”‚  â”‚ â—‹ GPT 5 Codex Low (OAuth) â†â”€â”€â”€â”€â”€â”€â”¼â”€â”€ name field            â”‚
â”‚  â”‚ â—‹ GPT 5 Codex Medium (OAuth)     â”‚                          â”‚
â”‚  â”‚ â—‹ GPT 5 Codex High (OAuth)       â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                                 â”‚
â”‚  Config Lookup (Plugin):                                       â”‚
â”‚  userConfig.models["gpt-5-codex-low"].options                  â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                       CONFIG KEY                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Internal Flow                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. User Selection                                              â”‚
â”‚     opencode run --model=openai/gpt-5-codex-low                â”‚
â”‚     OpenCode parses: providerID="openai"                        â”‚
â”‚                      modelID="gpt-5-codex-low" â† CONFIG KEY    â”‚
â”‚                                                                 â”‚
â”‚  2. OpenCode Provider Lookup                                    â”‚
â”‚     provider.info.models["gpt-5-codex-low"]                     â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                            CONFIG KEY                           â”‚
â”‚                                                                 â”‚
â”‚  3. Custom Loader Call (OpenAI)                                 â”‚
â”‚     getModel(sdk, "gpt-5-codex-low")                            â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                     CONFIG KEY                                  â”‚
â”‚                                                                 â”‚
â”‚  4. AI SDK Request Creation                                     â”‚
â”‚     { model: "gpt-5-codex-low", ... }                           â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                CONFIG KEY                                       â”‚
â”‚                                                                 â”‚
â”‚  5. Custom fetch() (Our Plugin)                                 â”‚
â”‚     body.model = "gpt-5-codex-low"                              â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                    CONFIG KEY                                   â”‚
â”‚                                                                 â”‚
â”‚  6. Plugin Config Lookup                                        â”‚
â”‚     userConfig.models["gpt-5-codex-low"].options                â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                         CONFIG KEY                              â”‚
â”‚     Result: { reasoningEffort: "low", ... } âœ… FOUND           â”‚
â”‚                                                                 â”‚
â”‚  7. Plugin Normalization                                        â”‚
â”‚     normalizeModel("gpt-5-codex-low")                           â”‚
â”‚     Returns: "gpt-5-codex" â† SENT TO CODEX API                 â”‚
â”‚                                                                 â”‚
â”‚  8. TUI Persistence                                             â”‚
â”‚     ~/.opencode/tui:                                            â”‚
â”‚       provider_id = "openai"                                    â”‚
â”‚       model_id = "gpt-5-codex-low" â† CONFIG KEY persisted      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Field Purpose Summary

### Config Key: The Real Identifier

```json
"gpt-5-codex-low": { ... }
 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
   CONFIG KEY
```

**Purpose:**
- ğŸ¯ **PRIMARY identifier** - used everywhere in OpenCode
- ğŸ¯ **Plugin receives this** - what our plugin sees in `body.model`
- ğŸ¯ **Config lookup key** - how plugin finds per-model options
- ğŸ¯ **Persisted value** - saved in TUI state

**Best Practice:** Use Codex CLI preset names (`gpt-5-codex-low`, `gpt-5-high`, etc.)

---

### `id` Field: Documentation/Metadata

```json
"id": "gpt-5-codex"
       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         ID FIELD
```

**Purpose:**
- ğŸ“ **Documents** what base model this variant uses
- ğŸ“ **Helps sorting** in model lists
- ğŸ“ **Clarity** - shows relationship between variants

**Best Practice:** Set to the base API model name (`gpt-5-codex`, `gpt-5`, etc.)

**Note:** For OpenAI provider, this is NOT sent to the API! The plugin normalizes the config key instead.

---

### `name` Field: UI Display

```json
"name": "GPT 5 Codex Low (OAuth)"
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              NAME FIELD
```

**Purpose:**
- ğŸ¨ **TUI display** - what users see in model picker
- ğŸ¨ **User-friendly** - can be descriptive
- ğŸ¨ **Differentiation** - helps distinguish from API key models

**Best Practice:** Human-friendly name with context (OAuth, API, subscription type, etc.)

---

## Real-World Examples

### Example 1: Our Current Config âœ…

```json
{
  "gpt-5-codex-low": {
    "id": "gpt-5-codex",
    "name": "GPT 5 Codex Low (OAuth)",
    "options": { "reasoningEffort": "low" }
  }
}
```

**When user selects `openai/gpt-5-codex-low`:**
- CLI: Uses `"gpt-5-codex-low"` (config key)
- TUI: Shows `"GPT 5 Codex Low (OAuth)"` (name field)
- Plugin receives: `body.model = "gpt-5-codex-low"` (config key)
- Plugin looks up: `models["gpt-5-codex-low"]` âœ… Found
- Plugin sends to API: `"gpt-5-codex"` (normalized)

**Result:** âœ… Everything works perfectly!

---

### Example 2: Multiple Variants of Same Model âœ…

```json
{
  "gpt-5-codex-low": {
    "id": "gpt-5-codex",
    "name": "GPT 5 Codex Low (OAuth)"
  },
  "gpt-5-codex-high": {
    "id": "gpt-5-codex",
    "name": "GPT 5 Codex High (OAuth)"
  }
}
```

**Why this works:**
- Config keys are different: `"gpt-5-codex-low"` vs `"gpt-5-codex-high"` âœ…
- Same `id` is fine - it's just metadata
- Different `name` values help distinguish in TUI

**Result:** âœ… Two variants of same base model, different settings

---

### Example 3: GPT-5.1 presets (recommended) âœ…

```json
{
  "gpt-5.1-codex-max": {
    "id": "gpt-5.1-codex-max",
    "name": "GPT 5.1 Codex Max (OAuth)",
    "options": { "reasoningEffort": "medium" }
  },
  "gpt-5.1-codex-low": {
    "id": "gpt-5.1-codex",
    "name": "GPT 5.1 Codex Low (OAuth)",
    "options": { "reasoningEffort": "low" }
  },
  "gpt-5.1-none": {
    "id": "gpt-5.1",
    "name": "GPT 5.1 None (OAuth)",
    "options": { "reasoningEffort": "none", "textVerbosity": "medium" }
  }
}
```

**Why this matters:**
- Config keys mirror the Codex CLI's 5.1 presets, making it obvious which tier you're targeting.
- `reasoningEffort: "none"` is only valid for GPT-5.1 general modelsâ€”the plugin automatically downgrades unsupported values for Codex/Codex Mini.
- `reasoningEffort: "xhigh"` is exclusive to `gpt-5.1-codex-max`; other models automatically clamp it to `high`.
- Legacy GPT-5, GPT-5-Codex, and Codex Mini presets automatically clamp unsupported values (`none` â†’ `minimal`/`low`, `minimal` â†’ `low` for Codex).
- Mixing GPT-5.1 and GPT-5 presets inside the same config is fineâ€”just keep config keys unique and let the plugin normalize them.


---

## Why We Need Different Config Keys

**Problem:** Need multiple configurations for the same API model

**Solution:** Different config keys â†’ same `id`

```json
{
  "gpt-5-codex-low": {          // â† Unique config key #1
    "id": "gpt-5-codex",         // â† Same base model
    "options": { "reasoningEffort": "low" }
  },
  "gpt-5-codex-medium": {       // â† Unique config key #2
    "id": "gpt-5-codex",         // â† Same base model
    "options": { "reasoningEffort": "medium" }
  },
  "gpt-5-codex-high": {         // â† Unique config key #3
    "id": "gpt-5-codex",         // â† Same base model
    "options": { "reasoningEffort": "high" }
  }
}
```

**Result:**
- 3 selectable variants in TUI âœ…
- Same API model (`gpt-5-codex`) âœ…
- Different reasoning settings âœ…
- Plugin correctly applies per-variant options âœ…

---

## Backwards Compatibility

### Config Changes are Safe âœ…

**Old Plugin + Old Config:**
```json
"GPT 5 Codex Low (ChatGPT Subscription)": {
  "id": "gpt-5-codex",
  "options": { "reasoningEffort": "low" }
}
```
**Result:** âŒ Per-model options broken (existing bug in old plugin)

**New Plugin + Old Config:**
```json
"GPT 5 Codex Low (ChatGPT Subscription)": {
  "id": "gpt-5-codex",
  "options": { "reasoningEffort": "low" }
}
```
**Result:** âœ… Per-model options work! (bug fixed)

**New Plugin + New Config:**
```json
"gpt-5-codex-low": {
  "id": "gpt-5-codex",
  "name": "GPT 5 Codex Low (OAuth)",
  "options": { "reasoningEffort": "low" }
}
```
**Result:** âœ… Per-model options work! (bug fixed + cleaner naming)

**Conclusion:**
- âœ… Existing configs continue to work
- âœ… New configs work better
- âœ… Users can migrate at their own pace

---

## Required Configuration Fields

### `store` Field: Critical for AI SDK 2.0.50+

**âš ï¸ Required as of AI SDK 2.0.50 (released Oct 12, 2025)**

```json
{
  "provider": {
    "openai": {
      "options": {
        "store": false
      }
    }
  }
}
```

**What it does:**
- `false` (required): Prevents AI SDK from using `item_reference` for conversation history
- `true` (default): Uses server-side storage with references (incompatible with Codex API)

**Why required:**
AI SDK 2.0.50 introduced automatic use of `item_reference` items to reduce payload size when `store: true`. However:
- Codex API requires `store: false` (stateless mode)
- `item_reference` items cannot be resolved without server-side storage
- Without this setting, multi-turn conversations fail with: `"Item with id 'fc_xxx' not found"`

**Where to set:**
```json
{
  "provider": {
    "openai": {
      "options": {
        "store": false  // â† Global: applies to all models
      },
      "models": {
        "gpt-5-codex-low": {
          "options": {
            "store": false  // â† Per-model: redundant but explicit
          }
        }
      }
    }
  }
}
```

**Recommendation:** Set in global `options` since it's required for all models using this plugin.

**Note:** The plugin also includes a `chat.params` hook that automatically injects `store: false`, but explicit configuration is recommended for clarity and forward compatibility.

---

## Recommended Structure

### Recommended: Config Key + Name âœ…

```json
{
  "gpt-5-codex-low": {
    "name": "GPT 5 Codex Low (OAuth)",
    "options": { "reasoningEffort": "low" }
  }
}
```

**Benefits:**
- âœ… Clean config key: `gpt-5-codex-low` (matches Codex CLI presets)
- âœ… Friendly display: `"GPT 5 Codex Low (OAuth)"` (UX)
- âœ… No redundant fields
- âœ… OpenCode auto-sets `id` to config key

**Why no `id` field?**
- For OpenAI provider, the `id` field is NOT used (custom loader receives config key)
- OpenCode defaults `id` to config key if omitted
- Including it is redundant and creates confusion

---

### Minimal Structure (Works but less friendly)

```json
{
  "gpt-5-codex-low": {
    "options": { "reasoningEffort": "low" }
  }
}
```

**What happens:**
- `id` defaults to: `"gpt-5-codex-low"` (config key)
- `name` defaults to: `"gpt-5-codex-low"` (config key)
- TUI shows: `"gpt-5-codex-low"` (less friendly)
- Plugin normalizes: `"gpt-5-codex-low"` â†’ `"gpt-5-codex"` for API
- **Works perfectly, just less user-friendly**

---

### With id Field (Redundant but Harmless)

```json
{
  "gpt-5-codex-low": {
    "id": "gpt-5-codex",
    "name": "GPT 5 Codex Low (OAuth)",
    "options": { "reasoningEffort": "low" }
  }
}
```

**What happens:**
- `id` field is stored but NOT used by OpenAI custom loader
- Adds documentation value but is technically redundant
- Works fine, just verbose

---

## Summary Table

| Use Case | Which Field? | Example Value |
|----------|-------------|---------------|
| **CLI `--model` flag** | Config Key | `openai/gpt-5-codex-low` |
| **Custom commands** | Config Key | `model: openai/gpt-5-codex-low` |
| **Agent config** | Config Key | `"model": "openai/gpt-5-codex-low"` |
| **TUI display** | `name` field | `"GPT 5 Codex Low (OAuth)"` |
| **Plugin config lookup** | Config Key | `models["gpt-5-codex-low"]` |
| **AI SDK receives** | Config Key | `body.model = "gpt-5-codex-low"` |
| **Plugin normalizes** | Transformed | `"gpt-5-codex"` (sent to API) |
| **TUI persistence** | Config Key | `model_id = "gpt-5-codex-low"` |
| **Documentation** | `id` field | `"gpt-5-codex"` (base model) |
| **Model sorting** | `id` field | Used for priority ranking |

---

## Key Insight for OpenAI Provider

```
CONFIG KEY is the real identifier! ğŸ‘‘
  â”œâ”€ Used for selection (CLI, TUI, commands)
  â”œâ”€ Used for persistence (saved to ~/.opencode/tui)
  â”œâ”€ Passed to custom loader (getModel receives this)
  â”œâ”€ Sent to AI SDK (body.model = this)
  â””â”€ Received by plugin (our plugin sees this)

id field is metadata ğŸ“
  â”œâ”€ Documents base model
  â”œâ”€ Used for sorting
  â””â”€ NOT sent to AI SDK (custom loader uses config key)

name field is UI sugar ğŸ¨
  â””â”€ Makes TUI model picker user-friendly
```

---

## Why The Bug Happened

**Old Plugin Logic (Broken):**
```typescript
const normalizedModel = normalizeModel(body.model);  // "gpt-5-codex-low" â†’ "gpt-5-codex"
const modelConfig = getModelConfig(normalizedModel, userConfig);  // Lookup "gpt-5-codex"
```

**Problem:**
- Plugin received: `"gpt-5-codex-low"` (config key)
- Plugin normalized first: `"gpt-5-codex"`
- Plugin looked up config: `models["gpt-5-codex"]` âŒ NOT FOUND
- Config key was: `models["gpt-5-codex-low"]`
- **Result:** Per-model options ignored!

**New Plugin Logic (Fixed):**
```typescript
const originalModel = body.model;  // "gpt-5-codex-low" (config key)
const normalizedModel = normalizeModel(body.model);  // "gpt-5-codex" (for API)
const modelConfig = getModelConfig(originalModel, userConfig);  // Lookup "gpt-5-codex-low" âœ…
```

**Fix:**
- Use original value (config key) for config lookup âœ…
- Normalize separately for API call âœ…
- **Result:** Per-model options applied correctly!

---

## Testing the Understanding

### Test Case 1: Which model does plugin send to API?

**Config:**
```json
{
  "my-custom-name": {
    "id": "gpt-5-codex",
    "name": "My Custom Display Name",
    "options": { "reasoningEffort": "high" }
  }
}
```

**User runs:** `--model=openai/my-custom-name`

**Question:** What model does plugin send to Codex API?

**Answer:**
1. Plugin receives: `body.model = "my-custom-name"`
2. Plugin normalizes: `"my-custom-name"` â†’ `"gpt-5-codex"` (contains "codex")
3. Plugin sends to API: `"gpt-5-codex"` âœ…

**The `id` field is NOT used for this!**

---

### Test Case 2: How does TUI know what to display?

**Config:**
```json
{
  "ugly-key-123": {
    "id": "gpt-5",
    "name": "Beautiful Display Name"
  }
}
```

**Question:** What does TUI model picker show?

**Answer:** `"Beautiful Display Name"` (from `name` field)

**If `name` was omitted:** Would show `"ugly-key-123"` (config key)

---

### Test Case 3: How does plugin find config?

**Config:**
```json
{
  "gpt-5-codex-low": {
    "id": "gpt-5-codex",
    "options": { "reasoningEffort": "low" }
  }
}
```

**User selects:** `openai/gpt-5-codex-low`

**Question:** How does plugin find the options?

**Answer:**
1. Plugin receives: `body.model = "gpt-5-codex-low"`
2. Plugin looks up: `userConfig.models["gpt-5-codex-low"]` âœ…
3. Plugin finds: `{ reasoningEffort: "low" }` âœ…

**The lookup uses config key, NOT the `id` field!**

---

## Common Mistakes

### âŒ Using id as Config Key

```json
{
  "gpt-5-codex": {  // âŒ Can't have multiple variants
    "id": "gpt-5-codex"
  }
}
```

### âŒ Thinking id Controls Plugin Lookup

```json
{
  "my-model": {
    "id": "gpt-5-codex-low",  // âŒ Plugin won't look up by this!
    "options": { ... }
  }
}
```

**Plugin looks up by:** `"my-model"` (config key), not `"gpt-5-codex-low"` (id)

### âŒ Forgetting name Field

```json
{
  "gpt-5-codex-low": {
    "id": "gpt-5-codex"
    // Missing: "name" field
  }
}
```

**Result:** TUI shows `"gpt-5-codex-low"` (works but less friendly)

---

---

## Cache Key Handling

### Dual Field Support

This plugin supports both camelCase and snake_case cache key fields for maximum compatibility:

```typescript
// Host provides camelCase (OpenCode SDK)
{
  "promptCacheKey": "cache-key-123",
  "messages": [...]
}

// Host provides snake_case (metadata)
{
  "prompt_cache_key": "cache-key-123", 
  "messages": [...]
}

// Plugin accepts both with snake_case priority
const cacheKey = request.prompt_cache_key || request.promptCacheKey;
```

**Priority Order:**
1. `prompt_cache_key` (snake_case) - from host or metadata
2. `promptCacheKey` (camelCase) - from OpenCode SDK
3. Fallback to generation if neither present

**Purpose:** Ensures cache continuity across different OpenCode runtime versions and request sources.

---

## See Also

- [CONFIG_FLOW.md](./CONFIG_FLOW.md) - Complete config system guide
- [ARCHITECTURE.md](./ARCHITECTURE.md) - Technical architecture
- [BUGS_FIXED.md](./BUGS_FIXED.md) - Bug fixes and testing
